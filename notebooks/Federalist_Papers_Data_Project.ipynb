{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Part 1 - Scraping The Federalist Papers ###\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import time\n",
    "\n",
    "os.chdir(\"Downloads/Project1/documents\")\n",
    "\n",
    "for i in range(85):\n",
    "    print(i+1)\n",
    "    if i < 9:\n",
    "        ID = \"0\" + str(i+1)\n",
    "    else:\n",
    "        ID = str(i+1)\n",
    "    r = requests.get(\"http://avalon.law.yale.edu/18th_century/fed%s.asp\" % ID)\n",
    "    s = BeautifulSoup(r.text)\n",
    "    ps = s.findAll(\"p\")\n",
    "    with open(ID + \".txt\", \"w\") as f:\n",
    "        for p in ps:\n",
    "            t = p.text\n",
    "            t = t.replace(\" Return to the Text\", \"\")\n",
    "            t = t.replace(\"Ã\\x95\", \"\")\n",
    "            f.write(t + \"\\n\")\n",
    "    time.sleep(30)\n",
    "\n",
    "\n",
    "author = []\n",
    "r = requests.get(\"https://www.congress.gov/resources/display/content/The+Federalist+Papers\")\n",
    "s = BeautifulSoup(r.text)\n",
    "table = s.find(\"table\", {\"class\": \"confluenceTable\"})\n",
    "rows = table.findAll(\"tr\")\n",
    "for row in rows[1:]:\n",
    "    author.append(row.findAll(\"td\")[2].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Part 2 - Mimicking the three Federalist authors ###\n",
    "\n",
    "\n",
    "import nltk\n",
    "import numpy\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "def draw_word(distrn):\n",
    "    words = list(distrn)\n",
    "    freqs = [freq for w, freq in distrn.items()]\n",
    "    total = sum(freqs)\n",
    "    probs = [freq/total for freq in freqs]\n",
    "    return numpy.random.choice(words, p=probs)\n",
    "\n",
    "def generate_with_trigrams(text, word=None, num=100):\n",
    "    tokens = nltk.tokenize.word_tokenize(text)\n",
    "    trigrams = nltk.trigrams(tokens)\n",
    "    condition_pairs = (((w0, w1), w2) for w0, w1, w2 in trigrams)\n",
    "    cfdist = nltk.ConditionalFreqDist(condition_pairs)\n",
    "    if word is None:\n",
    "        prev = draw_word(nltk.FreqDist(tokens))\n",
    "        word = draw_word(nltk.ConditionalFreqDist(nltk.bigrams(tokens))[prev])\n",
    "    elif len(word.split()) == 1:\n",
    "        prev = word\n",
    "        word = draw_word(nltk.ConditionalFreqDist(nltk.bigrams(tokens))[prev])\n",
    "        # will give an error if this pair doesn't show up in the text\n",
    "    else:\n",
    "        prev, word = word.split()[:2]\n",
    "    print(prev, end=' ')\n",
    "    for i in range(1, num):\n",
    "        print(word, end=' ')\n",
    "        prev, word = word, draw_word(cfdist[(prev, word)])\n",
    "\n",
    "\n",
    "# each author will have all his papers merged\n",
    "hamilton = \"\"\n",
    "madison = \"\"\n",
    "jay = \"\"\n",
    "\n",
    "docnames = [f for f in os.listdir() if f[-4:]==\".txt\"]\n",
    "docnames.sort()\n",
    "\n",
    "N = len(docnames)\n",
    "for i in range(N):\n",
    "    with open(docnames[i], 'r') as f:\n",
    "        if author[i] == \"Hamilton\":\n",
    "            hamilton += f.read() + \" \"\n",
    "        elif author[i] == \"Madison\":\n",
    "            madison += f.read() + \" \"\n",
    "        elif author[i] == \"Jay\":\n",
    "            jay += f.read() + \" \"\n",
    "\n",
    "len(hamilton)\n",
    "len(madison)\n",
    "len(jay)\n",
    "\n",
    "\n",
    "generate_with_trigrams(hamilton, \"The\")\n",
    "generate_with_trigrams(madison, \"The\")\n",
    "generate_with_trigrams(jay, \"The\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Part 3 - Creating data frame of token frequencies ###\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "N = len(docnames)\n",
    "tables = [None]*N\n",
    "for i in range(N):\n",
    "    with open(docnames[i], 'r') as f:\n",
    "        doc = f.read()\n",
    "        doc = doc.replace(\"To the People of the State of New York:\", \"\")\n",
    "        doc = doc.replace(\"PUBLIUS\", \"\")\n",
    "        doc = doc.replace(\"Ã¥\", \"\")\n",
    "        doc = re.sub(\"[0-9]+\", \"\", doc)\n",
    "        doc = doc.lower()\n",
    "        tokens = nltk.tokenize.word_tokenize(doc)\n",
    "        tables[i] = nltk.FreqDist(tokens)\n",
    "\n",
    "df = pd.DataFrame(tables)\n",
    "\n",
    "# fill in zeros\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# divide rows by totals\n",
    "for i in range(N):\n",
    "    s = sum(df.iloc[i])\n",
    "    df.iloc[i] = [n/s for n in df.iloc[i]]\n",
    "\n",
    "df.iloc[0] # check a row to make sure it worked\n",
    "\n",
    "# write as csv\n",
    "df.to_csv(\"../federalist.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# write authors as well\n",
    "with open(\"../authors.csv\", \"w\") as f:\n",
    "    f.write(\"author\\n\")\n",
    "    for a in author:\n",
    "        f.write(a + \"\\n\")\n",
    "\n",
    "# and write tokens\n",
    "with open(\"../tokens.csv\", \"w\") as f:\n",
    "    f.write(\"token\\n\")\n",
    "    for t in list(df):\n",
    "        f.write('\"' + t + '\"\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:scipybase_Jun2021]",
   "language": "python",
   "name": "conda-env-scipybase_Jun2021-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
